{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2cb11b",
   "metadata": {},
   "source": [
    "# Oveview\n",
    "\n",
    "This tutorial shows you how to use [DataStax Astra DB](https://docs.datastax.com/en/astra-serverless/docs/index.html), a fast and highly scalable vector database, to build a food recommendation system based on the similarity of historical food review comments.\n",
    "\n",
    "## DataSet\n",
    "\n",
    "The food review dataset used in this tutorial is a subset of the Amazon Fine Food Review dataset that has been preprocessed by OpenAI. The subset can be found at this [OpenAI GitHub link](https://github.com/openai/openai-cookbook/blob/main/examples/data/fine_food_reviews_1k.csv) and the full dataset can be found at this [Kaggle link](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews).\n",
    "\n",
    "## Text Embedding Model\n",
    "\n",
    "The text embedding model used in this tuorial is Google's [Vertex AI Gecko model](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings), ***textembedding-gecko***, which has a output dimension size of ***768***.\n",
    "\n",
    "With a little bit of tweaking, you can easily make this tutorial compatible with other text embedding modes, such as OpenAI's ***text-embedding-ada-002*** model ([link](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) that has a dimension size of ***1536*** or HugginFace's [MiniLM-L6-V2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) that has a output dimension size of ***384***.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "To run this tutorial,  you first need to meet the following prerequisites:\n",
    "1) Create a free-tier Astra account and create an Astra Vector Database. (Link: https://astra.datastax.com)\n",
    "2) Create a GCP service account with the necessary permissions, including access to Vertex AI.\n",
    "3) Optionally (but highly recommende), install `gcloud CLI`[link](https://cloud.google.com/sdk/docs/install) and `Astra CLI`[link](https://awesome-astra.github.io/docs/pages/astra/astra-cli/#1-installation) to make it easier to configure the connection to the remote Astra Vector database and the Google Vertex AI service.\n",
    "\n",
    "The tutorial procedure in the notebook below has been tested on a locally installed Jupyter notebook. If you want to run it on a cloud-based Jupyter notebook service, you may need to make some minor changes to the code, such as adding code to upload the required files to the cloud Jupyter notebook instance. The main workflow of the code remains the same, such as getting the embedding values for the food reviews, writing them to the database, and making recommendations by executing similarity-based vector searches.\n",
    "\n",
    "\n",
    "### Configure Astra Vector database connection\n",
    "\n",
    "Assuming you have `Astra CLI` installed and an Astra Vector database (as well as a keyspace) has already been precreated from the Astra Console, \n",
    "\n",
    "1) Run the following command to set up the Astra CLI enviornment. The following command is required to set up the Astra CLI environment. Once you have run this command, you will be able to run any other Astra CLI commands.\n",
    "```\n",
    "$ astra setup --token <AstraCS_token>\n",
    "```\n",
    "*NOTE*: The specified token value must start by *AstraCS:....*. You can get an AstraCS token by following the instructions in this [doc](https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html#_create_application_token). Make sure that you have the *Organization Administrator* role to avoid any permission limitations later on.\n",
    "\n",
    "2) Run the following command to create a dotenv environment for the database. This environment is stored in a hidden file called .env. and it contains all the system environment variables needed to connect to the database.\n",
    "\n",
    "```\n",
    "$ astra db create-dotenv <database_name> -k <keyspace_name>\n",
    "```\n",
    "\n",
    "### Verify connection to the Google Vertex AI service\n",
    "\n",
    "Assuming you have `gcloud CLI` installed and configured (see this [Google doc](https://cloud.google.com/sdk/docs/initializing)), run the following script to verify the connection to the Google Vertex AI service. If the connection is good, you should get a JSON output that includes the text embedding value for the input text.\n",
    "```\n",
    "MODEL_ID=\"textembedding-gecko\"\n",
    "PROJECT_ID=<your_project>\n",
    "REGION_NAME=<your_region>\n",
    "\n",
    "curl \\\n",
    "-X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${REGION_NAME}/publishers/google/models/${MODEL_ID}:predict -d \\\n",
    "$'{\n",
    "  \"instances\": [\n",
    "    { \"content\": \"What is life?\"}\n",
    "  ],\n",
    "}'\n",
    "\n",
    "```\n",
    "\n",
    "### Local Juypter instance\n",
    "\n",
    "Put the food review dataset in a subfolder `data` in the current folder, as below:\n",
    "\n",
    "```\n",
    "$ tree .\n",
    ".\n",
    "├── data\n",
    "│   └── fine_food_reviews_1k.csv\n",
    "└── food_review_vector_with_astra_db.ipyn\n",
    "```\n",
    "\n",
    "Start the local Jupyter instance from the current folder with the following command:\n",
    "```\n",
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv tiktoken google-cloud-aiplatform cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.concurrent import execute_concurrent_with_args\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "##\n",
    "# DO NOT change these values !\n",
    "#\n",
    "# - Concurrent batch prediction jobs (Quota limit is 5) (see: https://cloud.google.com/vertex-ai/docs/quotas)\n",
    "MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM = 5\n",
    "# - Google Gecko text embedding dimension is 768\n",
    "VERTEX_AI_EMBEDDING_DIMENSION=768\n",
    "\n",
    "\n",
    "##\n",
    "# Access the environment variables from the .env file for the corresponding Astra DB\n",
    "# NOTE: the \".env\" file is prepared using the following Astra CLI command\n",
    "#       astra db create-dotenv <astradb_name> -k <keyspace_name>\n",
    "#\n",
    "load_dotenv()\n",
    "\n",
    "##\n",
    "# Helper function to connect to Astra DB CQL session\n",
    "#\n",
    "def getAdbCqlSession(keyspace):\n",
    "    sec_bundle_file = os.environ.get('ASTRA_DB_SECURE_BUNDLE_PATH')\n",
    "    access_token = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\n",
    "    \n",
    "    cluster = Cluster(\n",
    "        cloud={\n",
    "            \"secure_connect_bundle\": sec_bundle_file,\n",
    "        },\n",
    "        auth_provider=PlainTextAuthProvider(\n",
    "            \"token\",\n",
    "            access_token,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    cqlSession = cluster.connect()\n",
    "    if len(keyspace) > 0:\n",
    "        cqlSession.set_keyspace(keyspace)\n",
    "    \n",
    "    return cqlSession\n",
    "    \n",
    "def getCQLKeyspace():\n",
    "    return os.environ.get('ASTRA_DB_KEYSPACE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef531e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the food review data\n",
    "#\n",
    "food_review_df = pd.read_csv('./data/fine_food_reviews_1k.csv')\n",
    "\n",
    "##\n",
    "# Add an empty column to store the embedding value for the combination of 'Summary' and 'Text' columns\n",
    "#\n",
    "food_review_df['Embedding'] = None\n",
    "\n",
    "##\n",
    "# Convert the input value (UTC in second) to the DateTime type \n",
    "# Otherwise, the input statement later will fail with incompatible type\n",
    "#\n",
    "food_review_df['Time'] = food_review_df['Time'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "print(food_review_df.info())\n",
    "food_review_df.head(n=5)\n",
    "\n",
    "total_row = food_review_df.shape[0]\n",
    "total_batch = math.ceil(total_row/MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM)\n",
    "print(f\"total_row={total_row}, total_batch={total_batch}\")\n",
    "\n",
    "##\n",
    "# Help function to get the starting row index of a batch\n",
    "#\n",
    "def get_batch_start_rowidx(bathidx):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    return batchidx * MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM\n",
    "\n",
    "##\n",
    "# Help function to get the ending row index of a batch\n",
    "#\n",
    "def get_batch_end_rowidx(batchidx):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    return min((batchidx+1) * MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM - 1, total_row - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed122819",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Helper function to get the text embedding vector using Google Vertex AI API\n",
    "#    \"textembedding-gecko@001\" embedding dimension is fixed at 768\n",
    "#\n",
    "def vertex_ai_text_embeddings(text_arr) -> list:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    embedding_mode_name = \"textembedding-gecko@001\"\n",
    "    model = TextEmbeddingModel.from_pretrained(embedding_mode_name)\n",
    "    embeddings = model.get_embeddings(text_arr)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return (end_time - start_time), embeddings\n",
    "\n",
    "##\n",
    "# Get the food review emeddings in batches using the Vertex AI API and update the dataframe accordingly\n",
    "#\n",
    "review_text_arr_by_batch = []\n",
    "fetch_embedding_batch_duration = []\n",
    "\n",
    "for batchidx in range(0, total_batch):    \n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    print(f\"Get embeddings of the food reviews for batch {batchidx+1} [{start_row_idx}, {end_row_idx}] ...\")\n",
    "\n",
    "    review_text_arr_by_batch.clear()\n",
    "    for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "        review_text_arr_by_batch.append(\n",
    "            food_review_df.iloc[rowidx]['Summary'] + \" : \" + food_review_df.iloc[rowidx]['Text'])\n",
    "    \n",
    "    # Call the Vertex embedding API in batch\n",
    "    batch_duration,embedding_list = vertex_ai_text_embeddings(review_text_arr_by_batch)\n",
    "    fetch_embedding_batch_duration.append(batch_duration)\n",
    "\n",
    "    # For each batch, update the embedding cell for each row in the data frame;\n",
    "    #   and isnert the record in the 'food_review' table\n",
    "    for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "        food_review_df.at[rowidx, 'Embedding'] = embedding_list[rowidx-start_row_idx].values\n",
    "\n",
    "print(f\"\"\"\\nVertex Emedding API call duration statistics (per batch): \n",
    "   min={np.min(fetch_embedding_batch_duration)}s, \n",
    "   max={np.max(fetch_embedding_batch_duration)}s, \n",
    "   avg={np.mean(fetch_embedding_batch_duration)}s\n",
    "\"\"\")\n",
    "food_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_keyspace = getCQLKeyspace()\n",
    "adb_cql_session = getAdbCqlSession(adb_keyspace)\n",
    "\n",
    "## \n",
    "# CQL statement to create the 'food_veiw' C* table\n",
    "#\n",
    "cql_schema_stmt=f\"\"\"CREATE TABLE IF NOT EXISTS {adb_keyspace}.food_review (\n",
    "  id int PRIMARY KEY,\n",
    "  time TIMESTAMP,\n",
    "  product_id TEXT,\n",
    "  user_id TEXT,\n",
    "  score INT,\n",
    "  summary TEXT,\n",
    "  text TEXT,\n",
    "  embedding VECTOR<FLOAT, {VERTEX_AI_EMBEDDING_DIMENSION}>\n",
    ");\"\"\"\n",
    "print(f\"cql_schema_stmt={cql_schema_stmt}\")\n",
    "\n",
    "adb_cql_session.execute(cql_schema_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# CQL prepared statement for inserting one record into the 'food_review' table\n",
    "#\n",
    "review_insert_stmt = cql_session.prepare(f\"\"\"\n",
    "    INSERT INTO {adb_keyspace}.food_review(id, time, product_id, user_id, score, summary, text, embedding) \n",
    "    VALUES(?,?,?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "##\n",
    "# Helper function to insert the food reviews with embedding values for a batch\n",
    "# - batchidx: the batch index\n",
    "# - concurrent: whether to use cassandra.concurrent library\n",
    "# \n",
    "def insert_with_embedding_batch(batchidx, concurrent=False):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    if concurrent == False:\n",
    "        for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "            cql_session.execute(review_insert_stmt, food_review_df.iloc[rowidx])\n",
    "    else:\n",
    "        parameters = []\n",
    "        for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "            parameters.append(food_review_df.iloc[rowidx])\n",
    "        execute_concurrent_with_args(cql_session,\n",
    "                                     review_insert_stmt, \n",
    "                                     parameters,\n",
    "                                     concurrency=MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return (end_time - start_time)\n",
    "\n",
    "##\n",
    "# Insert the food reviews with embeddings in batch\n",
    "#\n",
    "adb_insert_duration = []\n",
    "\n",
    "# Concurrent insert is much faster \n",
    "concurrent_insert = True\n",
    "\n",
    "for batchidx in range(0, total_batch):\n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    print(f\"Insert food review with the embedding value for batch {batchidx+1} [{start_row_idx}, {end_row_idx}] ...\")\n",
    "    batch_duration = insert_with_embedding_batch(batchidx, concurrent_insert)    \n",
    "    adb_insert_duration.append(batch_duration)\n",
    "    \n",
    "print(f\"\"\"\\nAstra DB C* table batch insert duration statistics with concurrent insert ({concurrent_insert}): \n",
    "   min={np.min(adb_insert_duration)}s, \n",
    "   max={np.max(adb_insert_duration)}s, \n",
    "   avg={np.mean(adb_insert_duration)}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25863679",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Helper function to query the food reviews using vector search and/or other regular searchs\n",
    "# - stmt: the CQL statement to execute\n",
    "# - top: Top N record to show (default is is not to show any queried results)\n",
    "#\n",
    "def food_review_query(stmt, top=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = cql_session.execute(stmt)\n",
    "\n",
    "    cnt=0\n",
    "    for result in results:\n",
    "        cnt += 1\n",
    "        if top and cnt<top:\n",
    "            print(result)\n",
    "            \n",
    "    end_time = time.time()\n",
    "        \n",
    "    return (end_time - start_time), cnt\n",
    "\n",
    "##\n",
    "# Define an SASI index on a regular column 'product_id' \n",
    "#\n",
    "product_index_creation_stmt=f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS food_review_product_index\n",
    "    ON {adb_keyspace}.food_review(product_id) USING 'StorageAttachedIndex';\n",
    "\"\"\"\n",
    "cql_session.execute(product_index_creation_stmt)\n",
    "\n",
    "##\n",
    "# Define an SASI index on the vector column 'embedding' \n",
    "# - default similarity comparison mode:\n",
    "#   * COSINE\n",
    "#   * DOT_PRODUCT\n",
    "#   * EUCLIDEAN\n",
    "ANN_INDEX_MODE = \"'COSINE'\"\n",
    "ann_index_creation_stmt=f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS food_review_ann_index\n",
    "    ON {adb_keyspace}.food_review(embedding) USING 'StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{ 'similarity_function': {ANN_INDEX_MODE} }};\n",
    "\"\"\"\n",
    "cql_session.execute(ann_index_creation_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration,query_embeddings = vertex_ai_text_embeddings([\"hamburger is good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_limit = 100\n",
    "\n",
    "# Pure vector search \n",
    "query_duration,cnt = food_review_query(f\"\"\"\n",
    "    SELECT \n",
    "        id, \n",
    "        time, \n",
    "        product_id, \n",
    "        user_id, score, \n",
    "        summary, \n",
    "        text\n",
    "    FROM {adb_keyspace}.food_review \n",
    "    ORDER BY embedding ANN OF {query_embeddings[0].values}\n",
    "    LIMIT {vector_query_limit};\n",
    "    \"\"\",\n",
    "top=2)\n",
    "\n",
    "print(f\"\"\"\\nPure vector search with maximum {vector_query_limit} records: \n",
    "   result_cnt={cnt}, \n",
    "   query_duration={query_duration}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both vector search and regular search\n",
    "query_duration,cnt = food_review_query(f\"\"\"\n",
    "    SELECT \n",
    "        id, \n",
    "        time, \n",
    "        product_id, \n",
    "        user_id, score, \n",
    "        summary, \n",
    "        text\n",
    "    FROM {adb_keyspace}.food_review \n",
    "    WHERE product_id in ('B0006UFY46', 'B0077HIJYS')\n",
    "    ORDER BY embedding ANN OF {query_embeddings[0].values}\n",
    "    LIMIT {vector_query_limit};\n",
    "    \"\"\",\n",
    "top=2)\n",
    "\n",
    "print(f\"\"\"\\nPure vector search with maximum {vector_query_limit} records: \n",
    "   result_cnt={cnt}, \n",
    "   query_duration={query_duration}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c36972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
