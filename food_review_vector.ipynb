{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv tiktoken google-cloud-aiplatform cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.concurrent import execute_concurrent_with_args\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "##\n",
    "# DO NOT change these values !\n",
    "#\n",
    "# - Concurrent batch prediction jobs (Quota limit is 5) (see: https://cloud.google.com/vertex-ai/docs/quotas)\n",
    "MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM = 5\n",
    "# - Google Gecko text embedding dimension is 768\n",
    "VERTEX_AI_EMBEDDING_DIMENSION=768\n",
    "\n",
    "\n",
    "##\n",
    "# Access the environment variables from the .env file for the corresponding Astra DB\n",
    "# NOTE: the \".env\" file is prepared using the following Astra CLI command\n",
    "#       astra db create-dotenv <astradb_name> -k <keyspace_name>\n",
    "#\n",
    "load_dotenv()\n",
    "\n",
    "##\n",
    "# Helper function to connect to Astra DB CQL session\n",
    "#\n",
    "def getAdbCqlSession(keyspace):\n",
    "    sec_bundle_file = os.environ.get('ASTRA_DB_SECURE_BUNDLE_PATH')\n",
    "    access_token = os.environ.get('ASTRA_DB_APPLICATION_TOKEN')\n",
    "    \n",
    "    cluster = Cluster(\n",
    "        cloud={\n",
    "            \"secure_connect_bundle\": sec_bundle_file,\n",
    "        },\n",
    "        auth_provider=PlainTextAuthProvider(\n",
    "            \"token\",\n",
    "            access_token,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    cqlSession = cluster.connect()\n",
    "    if len(keyspace) > 0:\n",
    "        cqlSession.set_keyspace(keyspace)\n",
    "    \n",
    "    return cqlSession\n",
    "    \n",
    "def getCQLKeyspace():\n",
    "    return os.environ.get('ASTRA_DB_KEYSPACE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef531e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the food review data\n",
    "#\n",
    "food_review_df = pd.read_csv('./data/fine_food_reviews_1k.csv')\n",
    "\n",
    "##\n",
    "# Add an empty column to store the embedding value for the combination of 'Summary' and 'Text' columns\n",
    "#\n",
    "food_review_df['Embedding'] = None\n",
    "\n",
    "##\n",
    "# Convert the input value (UTC in second) to the DateTime type \n",
    "# Otherwise, the input statement later will fail with incompatible type\n",
    "#\n",
    "food_review_df['Time'] = food_review_df['Time'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "print(food_review_df.info())\n",
    "food_review_df.head(n=5)\n",
    "\n",
    "total_row = food_review_df.shape[0]\n",
    "total_batch = math.ceil(total_row/MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM)\n",
    "print(f\"total_row={total_row}, total_batch={total_batch}\")\n",
    "\n",
    "##\n",
    "# Help function to get the starting row index of a batch\n",
    "#\n",
    "def get_batch_start_rowidx(bathidx):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    return batchidx * MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM\n",
    "\n",
    "##\n",
    "# Help function to get the ending row index of a batch\n",
    "#\n",
    "def get_batch_end_rowidx(batchidx):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    return min((batchidx+1) * MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM - 1, total_row - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed122819",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Helper function to get the text embedding vector using Google Vertex AI API\n",
    "#    \"textembedding-gecko@001\" embedding dimension is fixed at 768\n",
    "#\n",
    "def vertex_ai_text_embeddings(text_arr) -> list:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    embedding_mode_name = \"textembedding-gecko@001\"\n",
    "    model = TextEmbeddingModel.from_pretrained(embedding_mode_name)\n",
    "    embeddings = model.get_embeddings(text_arr)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return (end_time - start_time), embeddings\n",
    "\n",
    "##\n",
    "# Get the food review emeddings in batches using the Vertex AI API and update the dataframe accordingly\n",
    "#\n",
    "review_text_arr_by_batch = []\n",
    "fetch_embedding_batch_duration = []\n",
    "\n",
    "for batchidx in range(0, total_batch):    \n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    print(f\"Get embeddings of the food reviews for batch {batchidx+1} [{start_row_idx}, {end_row_idx}] ...\")\n",
    "\n",
    "    review_text_arr_by_batch.clear()\n",
    "    for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "        review_text_arr_by_batch.append(\n",
    "            food_review_df.iloc[rowidx]['Summary'] + \" : \" + food_review_df.iloc[rowidx]['Text'])\n",
    "    \n",
    "    # Call the Vertex embedding API in batch\n",
    "    batch_duration,embedding_list = vertex_ai_text_embeddings(review_text_arr_by_batch)\n",
    "    fetch_embedding_batch_duration.append(batch_duration)\n",
    "\n",
    "    # For each batch, update the embedding cell for each row in the data frame;\n",
    "    #   and isnert the record in the 'food_review' table\n",
    "    for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "        food_review_df.at[rowidx, 'Embedding'] = embedding_list[rowidx-start_row_idx].values\n",
    "\n",
    "print(f\"\"\"\\nVertex Emedding API call duration statistics (per batch): \n",
    "   min={np.min(fetch_embedding_batch_duration)}s, \n",
    "   max={np.max(fetch_embedding_batch_duration)}s, \n",
    "   avg={np.mean(fetch_embedding_batch_duration)}s\n",
    "\"\"\")\n",
    "food_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_keyspace = getCQLKeyspace()\n",
    "adb_cql_session = getAdbCqlSession(adb_keyspace)\n",
    "\n",
    "## \n",
    "# CQL statement to create the 'food_veiw' C* table\n",
    "#\n",
    "cql_schema_stmt=f\"\"\"CREATE TABLE IF NOT EXISTS {adb_keyspace}.food_review (\n",
    "  id int PRIMARY KEY,\n",
    "  time TIMESTAMP,\n",
    "  product_id TEXT,\n",
    "  user_id TEXT,\n",
    "  score INT,\n",
    "  summary TEXT,\n",
    "  text TEXT,\n",
    "  embedding VECTOR<FLOAT, {VERTEX_AI_EMBEDDING_DIMENSION}>\n",
    ");\"\"\"\n",
    "print(f\"cql_schema_stmt={cql_schema_stmt}\")\n",
    "\n",
    "adb_cql_session.execute(cql_schema_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# CQL prepared statement for inserting one record into the 'food_review' table\n",
    "#\n",
    "review_insert_stmt = cql_session.prepare(f\"\"\"\n",
    "    INSERT INTO {adb_keyspace}.food_review(id, time, product_id, user_id, score, summary, text, embedding) \n",
    "    VALUES(?,?,?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "##\n",
    "# Helper function to insert the food reviews with embedding values for a batch\n",
    "# - batchidx: the batch index\n",
    "# - concurrent: whether to use cassandra.concurrent library\n",
    "# \n",
    "def insert_with_embedding_batch(batchidx, concurrent=False):\n",
    "    assert batchidx >=0 and batchidx <= total_batch\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    if concurrent == False:\n",
    "        for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "            cql_session.execute(review_insert_stmt, food_review_df.iloc[rowidx])\n",
    "    else:\n",
    "        parameters = []\n",
    "        for rowidx in range(start_row_idx, end_row_idx+1):\n",
    "            parameters.append(food_review_df.iloc[rowidx])\n",
    "        execute_concurrent_with_args(cql_session,\n",
    "                                     review_insert_stmt, \n",
    "                                     parameters,\n",
    "                                     concurrency=MAX_ALLOWED_CONCURRENT_PREDICTION_JOB_NUM)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return (end_time - start_time)\n",
    "\n",
    "##\n",
    "# Insert the food reviews with embeddings in batch\n",
    "#\n",
    "adb_insert_duration = []\n",
    "\n",
    "# Concurrent insert is much faster \n",
    "concurrent_insert = True\n",
    "\n",
    "for batchidx in range(0, total_batch):\n",
    "    start_row_idx = get_batch_start_rowidx(batchidx)\n",
    "    end_row_idx = get_batch_end_rowidx(batchidx)\n",
    "    \n",
    "    print(f\"Insert food review with the embedding value for batch {batchidx+1} [{start_row_idx}, {end_row_idx}] ...\")\n",
    "    batch_duration = insert_with_embedding_batch(batchidx, concurrent_insert)    \n",
    "    adb_insert_duration.append(batch_duration)\n",
    "    \n",
    "print(f\"\"\"\\nAstra DB C* table batch insert duration statistics with concurrent insert ({concurrent_insert}): \n",
    "   min={np.min(adb_insert_duration)}s, \n",
    "   max={np.max(adb_insert_duration)}s, \n",
    "   avg={np.mean(adb_insert_duration)}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25863679",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Helper function to query the food reviews using vector search and/or other regular searchs\n",
    "# - stmt: the CQL statement to execute\n",
    "# - top: Top N record to show (default is is not to show any queried results)\n",
    "#\n",
    "def food_review_query(stmt, top=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = cql_session.execute(stmt)\n",
    "\n",
    "    cnt=0\n",
    "    for result in results:\n",
    "        cnt += 1\n",
    "        if top and cnt<top:\n",
    "            print(result)\n",
    "            \n",
    "    end_time = time.time()\n",
    "        \n",
    "    return (end_time - start_time), cnt\n",
    "\n",
    "##\n",
    "# Define an SASI index on a regular column 'product_id' \n",
    "#\n",
    "product_index_creation_stmt=f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS food_review_product_index\n",
    "    ON {adb_keyspace}.food_review(product_id) USING 'StorageAttachedIndex';\n",
    "\"\"\"\n",
    "cql_session.execute(product_index_creation_stmt)\n",
    "\n",
    "##\n",
    "# Define an SASI index on the vector column 'embedding' \n",
    "# - default similarity comparison mode:\n",
    "#   * COSINE\n",
    "#   * DOT_PRODUCT\n",
    "#   * EUCLIDEAN\n",
    "ANN_INDEX_MODE = \"'COSINE'\"\n",
    "ann_index_creation_stmt=f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS food_review_ann_index\n",
    "    ON {adb_keyspace}.food_review(embedding) USING 'StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{ 'similarity_function': {ANN_INDEX_MODE} }};\n",
    "\"\"\"\n",
    "cql_session.execute(ann_index_creation_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration,query_embeddings = vertex_ai_text_embeddings([\"hamburger is good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_limit = 100\n",
    "\n",
    "# Pure vector search \n",
    "query_duration,cnt = food_review_query(f\"\"\"\n",
    "    SELECT \n",
    "        id, \n",
    "        time, \n",
    "        product_id, \n",
    "        user_id, score, \n",
    "        summary, \n",
    "        text\n",
    "    FROM {adb_keyspace}.food_review \n",
    "    ORDER BY embedding ANN OF {query_embeddings[0].values}\n",
    "    LIMIT {vector_query_limit};\n",
    "    \"\"\",\n",
    "top=2)\n",
    "\n",
    "print(f\"\"\"\\nPure vector search with maximum {vector_query_limit} records: \n",
    "   result_cnt={cnt}, \n",
    "   query_duration={query_duration}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both vector search and regular search\n",
    "query_duration,cnt = food_review_query(f\"\"\"\n",
    "    SELECT \n",
    "        id, \n",
    "        time, \n",
    "        product_id, \n",
    "        user_id, score, \n",
    "        summary, \n",
    "        text\n",
    "    FROM {adb_keyspace}.food_review \n",
    "    WHERE product_id in ('B0006UFY46', 'B0077HIJYS')\n",
    "    ORDER BY embedding ANN OF {query_embeddings[0].values}\n",
    "    LIMIT {vector_query_limit};\n",
    "    \"\"\",\n",
    "top=2)\n",
    "\n",
    "print(f\"\"\"\\nPure vector search with maximum {vector_query_limit} records: \n",
    "   result_cnt={cnt}, \n",
    "   query_duration={query_duration}s\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5720bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
